{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "409ad774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import bentoml\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edf8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c53ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)\n",
    "\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n",
    "\n",
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb890c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = (df_train.status == 'default').astype('int').values\n",
    "y_test = (df_test.status == 'default').astype('int').values\n",
    "\n",
    "del df_train['status']\n",
    "del df_test['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea83a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train.fillna(0).to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "test_dicts = df_test.fillna(0).to_dict(orient='records')\n",
    "X_test = dv.transform(test_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26897f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=200,\n",
       "                       random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=200,\n",
       "                       random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=200,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                            max_depth=10,\n",
    "                            min_samples_leaf=3,\n",
    "                            random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc774c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10805421",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24db859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"credit_risk_model:dmtxcn2trc7g4aaq\", path=\"C:\\Users\\User\\bentoml\\models\\credit_risk_model\\dmtxcn2trc7g4aaq\\\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bentoml.xgboost.save_model(\n",
    "    'credit_risk_model',\n",
    "    model,\n",
    "    custom_objects={\n",
    "        'dictVectorizer': dv\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd2ae15",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install BentoML\n",
    "* What's the version of BentoML you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "821064ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bentoml, version 1.0.7\n"
     ]
    }
   ],
   "source": [
    "!bentoml -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd8e01",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Run the notebook which contains the xgboost model from module 6 i.e previous module and save the xgboost model with BentoML. To make it easier for you we have prepared this [notebook](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/07-bentoml-production/code/train.ipynb). \n",
    "\n",
    "\n",
    "How big approximately is the saved BentoML model? Size can slightly vary depending on your local development environment.\n",
    "Choose the size closest to your model.\n",
    "\n",
    "* 924kb\n",
    "* 724kb\n",
    "* 114kb\n",
    "* 8kb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cde0a6",
   "metadata": {},
   "source": [
    "Go to the folder: given as path in the output of the cell above. \n",
    "That is in my case `\"C:\\Users\\User\\bentoml\\models\\credit_risk_model\\dmtxcn2trc7g4aaq\\\"`\n",
    "\n",
    "I used gitbash here and need to remove the last slash and use the single or double quotes. \\\n",
    "`cd 'C:/Users/User/bentoml/models/credit_risk_model/dmtxcn2trc7g4aaq'`\n",
    "\n",
    "Alternatively, the changing the Windows' backslash `\\` with to the Unix's slash `/` also works without the quotes. \\\n",
    "`cd C:Users/User/bentoml/models/credit_risk_model/dmtxcn2trc7g4aaq`\n",
    "\n",
    "Then executing the `ls -las` command gives sizes in kiloBytes, which is ~ 200 kB -> closest to 114 kB\n",
    "![Model_Size](./src/model_size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5828a08",
   "metadata": {},
   "source": [
    "OR simply run in command line: \\\n",
    "`bentoml models list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23a00f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tag                          Module           Size        Creation Time       \n",
      " credit_risk_model:dmtxcn2t…  bentoml.xgboost  197.77 KiB  2022-10-24 13:39:15 \n"
     ]
    }
   ],
   "source": [
    "!bentoml models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3002e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: credit_risk_model                                                        \n",
      "version: dmtxcn2trc7g4aaq                                                      \n",
      "module: bentoml.xgboost                                                        \n",
      "labels: {}                                                                     \n",
      "options:                                                                       \n",
      "  model_class: Booster                                                         \n",
      "metadata: {}                                                                   \n",
      "context:                                                                       \n",
      "  framework_name: xgboost                                                      \n",
      "  framework_versions:                                                          \n",
      "    xgboost: 1.6.1                                                             \n",
      "  bentoml_version: 1.0.7                                                       \n",
      "  python_version: 3.9.12                                                       \n",
      "signatures:                                                                    \n",
      "  predict:                                                                     \n",
      "    batchable: false                                                           \n",
      "api_version: v2                                                                \n",
      "creation_time: '2022-10-24T10:39:15.458079+00:00'                              \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "# Details of the model..\n",
    "!bentoml models get credit_risk_model:dmtxcn2trc7g4aaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50db2571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"seniority\": 3,\n",
      "  \"home\": \"owner\",\n",
      "  \"time\": 36,\n",
      "  \"age\": 26,\n",
      "  \"marital\": \"single\",\n",
      "  \"records\": \"no\",\n",
      "  \"job\": \"freelance\",\n",
      "  \"expenses\": 35,\n",
      "  \"income\": 0.0,\n",
      "  \"assets\": 60000.0,\n",
      "  \"debt\": 3000.0,\n",
      "  \"amount\": 800,\n",
      "  \"price\": 1000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "request = df_test.iloc[0].to_dict()\n",
    "print(json.dumps(request, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23704181",
   "metadata": {},
   "source": [
    "## Another email from your manager\n",
    "\n",
    "Great job recruit! Looks like I won't be having to go back to the procurement team. Thanks for the information.\n",
    "\n",
    "However, I just got word from one of the teams that's using one of our ML services and they're saying our service is \"broken\"\n",
    "and their trying to blame our model. I looked at the data their sending and it's completely bogus. I don't want them\n",
    "to send bad data to us and blame us for our models. Could you write a pydantic schema for the data that they should be sending?\n",
    "That way next time it will tell them it's their data that's bad and not our model.\n",
    "\n",
    "Thanks,\n",
    "\n",
    "Mr McManager\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Say you have the following data that you're sending to your service:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"Tim\",\n",
    "  \"age\": 37,\n",
    "  \"country\": \"US\",\n",
    "  \"rating\": 3.14\n",
    "}\n",
    "```\n",
    "\n",
    "What would the pydantic class look like? You can name the class `UserProfile`.\n",
    "\n",
    "\n",
    "## Email from your CEO\n",
    "\n",
    "Good morning! I hear you're the one to go to if I need something done well! We've got a new model that a big client\n",
    "needs deployed ASAP. I need you to build a service with it and test it against the old model and make sure that it performs\n",
    "better, otherwise we're going to lose this client. All our hopes are with you!\n",
    "\n",
    "Thanks,\n",
    "\n",
    "CEO of Acme Corp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a55ac",
   "metadata": {},
   "source": [
    "The answer:\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    country: str\n",
    "    rating: float\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab5fed",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "We've prepared a model for you that you can import using:\n",
    "\n",
    "```bash\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel.bentomodel\n",
    "bentoml models import coolmodel.bentomodel\n",
    "```\n",
    "\n",
    "What version of scikit-learn was this model trained with?\n",
    "\n",
    "* 1.1.1\n",
    "* 1.1.2\n",
    "* 1.1.3\n",
    "* 1.1.4\n",
    "* 1.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85515a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1724  100  1724    0     0   1285      0  0:00:01  0:00:01 --:--:--  1287\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel.bentomodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d1a18",
   "metadata": {},
   "source": [
    "After importing the model as follows: \\\n",
    "`!bentoml models import coolmodel.bentomodel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e62fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tag                          Module           Size        Creation Time       \n",
      " credit_risk_model:dmtxcn2t…  bentoml.xgboost  197.77 KiB  2022-10-24 13:39:15 \n",
      " mlzoomcamp_homework:qtzdz3…  bentoml.sklearn  5.79 KiB    2022-10-13 23:42:14 \n"
     ]
    }
   ],
   "source": [
    "!bentoml models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e751f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: mlzoomcamp_homework                                                      \n",
      "version: qtzdz3slg6mwwdu5                                                      \n",
      "module: bentoml.sklearn                                                        \n",
      "labels: {}                                                                     \n",
      "options: {}                                                                    \n",
      "metadata: {}                                                                   \n",
      "context:                                                                       \n",
      "  framework_name: sklearn                                                      \n",
      "  framework_versions:                                                          \n",
      "    scikit-learn: 1.1.1                                                        \n",
      "  bentoml_version: 1.0.7                                                       \n",
      "  python_version: 3.9.12                                                       \n",
      "signatures:                                                                    \n",
      "  predict:                                                                     \n",
      "    batchable: false                                                           \n",
      "api_version: v1                                                                \n",
      "creation_time: '2022-10-13T20:42:14.411084+00:00'                              \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "# make sure to get full tag in the command line, as it is trimmed in the Jupyter notebook.\n",
    "!bentoml models get mlzoomcamp_homework:qtzdz3slg6mwwdu5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b7c46",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Create a bento out of this scikit-learn model. The output type for this endpoint should be `NumpyNdarray()`\n",
    "\n",
    "Send this array to the Bento:\n",
    "\n",
    "```\n",
    "[[6.4,3.5,4.5,1.2]]\n",
    "```\n",
    "\n",
    "You can use curl or the Swagger UI. What value does it return? \n",
    "\n",
    "* 0\n",
    "* 1\n",
    "* 2\n",
    "* 3\n",
    "\n",
    "(Make sure your environment has Scikit-Learn installed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44a931cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input array shape to enforce in service2.py\n",
    "input_data = [[6.4,3.5,4.5,1.2]]\n",
    "np.array(input_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb4e3d",
   "metadata": {},
   "source": [
    "After running the service2.py like below, we run the next cell\\\n",
    "`bentoml serve service2.py:svc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11ee19f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(requests.post(\n",
    "     \"http://localhost:3000/classify/\",\n",
    "     headers={\"content-type\": \"application/json\"},\n",
    "     data= str(input_data)\n",
    " ).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079ddfd",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Ensure to serve your bento with `--production` for this question\n",
    "\n",
    "Install locust using:\n",
    "\n",
    "```bash\n",
    "pip install locust\n",
    "```\n",
    "\n",
    "Use the following locust file: [locustfile.py](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/cohorts/2022/07-bento-production/locustfile.py)\n",
    "\n",
    "Ensure that it is pointed at your bento's endpoint (In case you didn't name your endpoint \"classify\")\n",
    "\n",
    "Configure 100 users with ramp time of 10 users per second. Click \"Start Swarming\" and ensure that it is working.\n",
    "\n",
    "Now download a second model with this command:\n",
    "\n",
    "```bash\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel\n",
    "```\n",
    "\n",
    "Or you can download with this link as well:\n",
    "[https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel](https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel)\n",
    "\n",
    "Now import the model:\n",
    "\n",
    "```bash\n",
    "bentoml models import coolmodel2.bentomodel\n",
    "```\n",
    "\n",
    "Update your bento's runner tag and test with both models. Which model allows more traffic (more throughput) as you ramp up the traffic?\n",
    "\n",
    "**Hint 1**: Remember to turn off and turn on your bento service between changing the model tag. Use Ctl-C to close the service in between trials.\n",
    "\n",
    "**Hint 2**: Increase the number of concurrent users to see which one has higher throughput\n",
    "\n",
    "Which model has better performance at higher volumes?\n",
    "\n",
    "* The first model\n",
    "* The second model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba304aa",
   "metadata": {},
   "source": [
    "After testing both models in the `production_tests folder` by changing the python-file in `bentofile.yaml` there as below: \\\n",
    "service3.py -> Model1 \\\n",
    "service4.py -> Model2 \n",
    "\n",
    "Then building these models each time and running in production using `bentoml serve --production` and measuring with the locust:\n",
    "\n",
    "Locus test results of the First Model:\n",
    "![Model1Test](./src/model1test4.png)\n",
    "\n",
    "And for the Second Model:\n",
    "![Model2Test](./src/model2test4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437171f5",
   "metadata": {},
   "source": [
    "I think we can deduce that Model2 performs better because it has higher RPS(req per sec) than the Model1, even though it has worse stats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4aa285",
   "metadata": {},
   "source": [
    "---\n",
    "The end of the Week 7 assignment.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
